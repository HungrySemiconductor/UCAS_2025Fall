| 位置                   | 题目                             |
| ---------------------- | -------------------------------- |
| 1-77                   | 生命周期模型、数据科学探索       |
| 6-56                   | 数据科学探索                     |
| 2-29、30               | CMMI成熟度等级                   |
| 2-80、94 过程88 产品89 | CMMI绩效改进：GQM 目标-问题-度量 |
| 3-41 会议58 待办64     | 敏捷方法最佳实践                 |
| 4-8、9 DevOps 4-19     | 可视化看板、WIP限制 支撑DevOps   |
| 4-79                   | OKR 目标(定性)-关键结果(定量)    |
| 5-66、100              | AI模型与系统、模型准确率陷阱     |
| 6-11                   | 分层目标：领先、系统、用户、模型 |
| 7-55、60 因素55 模式60 | 部署模式：混合、后端、云端       |
| 7-99、100              | 交互模式：自动、增强             |



# 1-77 生命周期模型、数据科学探索

**Q：使用课程Lecture-1中给出的生命周期检查单，假设你处于课程最开始讨论的案例研究中描述的情况，你会为项目选择哪个生命周期模型或者生命周期模型的组合简单阐述你的理由。**

> 我会为该项目选择螺旋模型。
>
> 1. 该项目初期扩大规模、加班、雇佣顶尖人员，资源充足；但中后期由于团队协作存在问题，员工的变更、代码变“黑盒”，说明该项目的全部资源并不是稳定可用的，且用户需求不明确、规范变换导致的变更，都说明团队对问题域理解“弱”，均不符合“瀑布模型”的准则。
>
> 2. 该案例中的产品“智能家居平台”涉及硬件、软件、通信等多个模块，项目的复杂性高，“增量、螺旋”符合该种情况。
>
> 3. 该项目的每个环节都存在一定风险，“进度压缩、需求变化、人员变更”等问题长期积累以至于最终难以化解，所以选取的模型一定要具备风险管理视角，“快速、演化、螺旋”符合该种情况。
> 4. 该项目不仅在初期需求变化多，在中后期还出现了行业规范变化，需要更加灵活的开发模式，“演化、螺旋”符合该种情况。
>
> 综上所述，我认为本案例最理想的模型是螺旋模型。

**Q：以本课程lecture-1中进行的选择生命周期模型的练习为基础，拓展思考以下问题： 假定公司决定开发lecture-6中的“跌倒检测”系统，你会为该项目选择什么样的生命周期模型和数据科学轨迹的组合.**

>生命周期模型：敏捷开发，在短时周期内进行迭代，逐步完善核心功能，并能快速响应用户反馈和测试中发现的问题
>
>数据科学轨迹组合：目标探索—数据价值探索—数据源探索—数据采集—数据准备—建模—评估—部署（循环数据价值探索至部署）

![image-20251229093955274](E:\Typora\Typora\coding-study\image-20251229093955274.png)

>**本项目采取‘双轨并行’模式。传统软件开发遵循 [某生命周期]，而模型训练遵循 [数据轨迹]。**
>
>- 起点	
>  - 由于 [目标是否明确]，我们将从 **[起点，如：数据价值探索]** 开始，确保模型研发与业务价值对齐
>  - 业务痛点不明确：目标探索
>  - 已有大量数据但不知道能干啥：数据价值探索
>  - 模型评估阶段欠拟合：回溯到 “数据准备——数据源探索 ”

### 1. 选择“螺旋+增量”的金句：

- **核心准则**：需求明确度、项目复杂度、风险水平、用户参与度 
- **适用场景：** 硬件+软件、高风险、需求不确定、大项目。
  	1. 该项目初期 [资源充足] 但 [需求边界模糊]，中后期面临 [人员变更/黑盒代码] 等管理挑战，单一的瀑布模型无法应对中途变更，而螺旋模型允许在每个阶段进行评估与修正
   	2. 考虑到该项目涉及 [硬件/通信/算法] 等多个复杂模块，需通过增量开发降低交付压力
   	3.  [技术/规范/市场] 存在极高的不确定性，需要灵活调整，项目 [技术难度高] 该算法是领域难题，存在 [高技术风险]，通过周期的迭代进行风险分析，能够有效避免 [后期缺陷积压/进度失控] 的灾难性后果
   	4. **排除瀑布模型，因为该项目存在[具体风险]，瀑布模型无法通过风险分析环提前规避！！！**

### 2. 选择“敏捷/演化”的金句：

- **适用场景：** 纯软件、用户反馈驱动、快速占领市场。
- **句式：** “项目处于 [新兴市场/探索阶段]，用户对 [具体功能] 的偏好尚不明确，初始需求模糊且后期变动大，符合演化/敏捷特征，采用敏捷开发可以通过 **‘短周期迭代’和‘持续交付’**，快速获取 [真实用户反馈]，从而实现产品的快速进化。”

### 3. 数据科学探索

- （无目标）**目标探索 (Goal Exploration)：** “首先明确业务痛点，将 [业务问题] 转化为 [数据科学问题]，定义成功的标准。”
- （无特征数据）**数据价值与源探索 (Data Value/Source Exploration)：** “评估现有数据的 [质量/维度/覆盖率]，寻找能支撑 [模型预测] 的核心特征来源。”
- （无数据）**数据采集与准备 (Data Collection & Preparation)：** “通过 [传感器/日志/数据库] 进行数据清洗与特征工程，解决数据 [缺失/不平衡/噪声] 问题。”
- （无建模）**建模与评估 (Modeling & Evaluation)：** “选择适合的算法进行训练，并使用 [交叉验证/A-B Test] 确保模型在 [未见数据] 上的泛化能力。”
- **部署与循环 (Deployment & Loop)：** “模型上线后，需建立 **‘闭环反馈机制’**。一旦 [业务环境/用户行为] 发生偏移，立即返回 [数据准备/建模] 阶段进行迭代。”

<img src="E:\Typora\Typora\coding-study\image-20251228214159553.png" alt="image-20251228214159553" style="zoom:67%;" />

---

<img src="E:\Typora\Typora\coding-study\image-20251228214239781.png" alt="image-20251228214239781" style="zoom:67%;" />

图中显示旅游、保险和信用卡示例的三种不同轨迹：

1、推荐连接城镇旅游景点的**旅行线路的产品**，可能基于导航和地图app收集的位置跟踪数据。为了构建这样一个项目，人们可能会**从一个具体的目标开始**，并探索是否有足够的用户位置历史数据可用或可以获得。然后，在探索如何最好地将结果呈现给用户之前，将经历传统的数据准备和建模阶段。

2、一家保险公司试图**改进他们的模型**，以根据驾驶员的行为和车内传感器对驾驶员的风险进行评分。在这里，需要对现有产品进行改进，并且在深入研究数据探索和建模之前需要更好地理解业务用例。团队可能会花费大量时间来探索可能提供新见解的新数据源，并可能讨论此数据或数据收集策略的成本和收益（例如，在客户汽车中安装传感器）。

3、信用卡公司可能希望向其他公司（零售商、餐馆）出售有关不同人（国籍）在不同时间和不同地点**倾向于购买哪种产品**的数据。他们可能会在不知道什么样的数据可能对什么样的客户感兴趣的情况下**探索现有数据**。他们可能会积极地在数据中寻找有趣的叙事，提出诸如“有没有想过法国人什么时候买他们的食物？” 或“德国人度假时涌向哪些地方？”之类的问题。

# 2-29 CMMI成熟度等级

**Q： 以本课程第一讲的案例研究背景为例，结合CMMI成熟度等级的定义，你认为案例中的ABC公司处于CMMI成熟度等级的第几级，简单说明理由。**

> 我认为其处于CMMI成熟度1级，原因如下：
>
> 1. 该公司缺乏基本项目管理过程
>
> 2. 需求与计划的变更随意
>
> 3. 项目执行混乱，团队没有协调
> 4. 软件部虽然有大量的经验积累，但并未建立机制以保存复用
> 5. 早期没有开展的质量检查，测试到最后才开始，缺陷激增

- **1级（初步）**：该公司的过程具有**‘随意性’和‘临时性’**，不可预测且被动项目的成功高度依赖于 [个人英雄主义/核心技术骨干]。缺乏健全的管理实践，测试环节被压后至 [最后阶段]，导致 [缺陷激增/救火式开发]。可以完成工作，但通常会延期且超预算
- **2级（管理）：** 建立了基本的项目规划、执行、度量和控制，但是只针对特定项目，经验无法在全公司范围内 [复用/沉淀]。
- **3级（定义）：**建立了一组标准过程，所有项目都根据 [组织标准] 进行裁剪，实现了过程的标准化。
- **4级（量化管理）**：组织以数据为导向提出量化的性能改进目标，目标可预测且一致，可以满足内外部利益相关方需求
- **5级（优化）**：组织专注于持续改进，并致力于转变和应对机遇与变化，其稳定性为敏捷和创新提供了平台，管理者能够有效地评估并跟踪变化的影响和有效性

---

# 2-80 GQM 目标-问题-度量

**Q：结合本课程第一讲中的案例背景：ABC公司采用目标-问题-度量（GQM）方法启动了一个度量程序，拟在公司范围内针对改进系统测试过程的缺陷检测能力开展度量。 请根据该度量目标，定义3个相关问题，并针对每个问题指定1个度量**。

>Q1：当前系统测试过程的缺陷检测能力如何？
>
>M1：系统测试发现的缺陷个数
>
>Q2：系统测试发现的缺陷对系统的影响情况？
>
>M2：不同影响程度的缺陷数量分别占总缺陷数量的比例（须事先定义缺陷严重等级）
>
>Q3：系统缺陷检测能力改进情况如何？
>
>M3：系统测试某阶段发现的缺陷个数占项目全过程发现的缺陷总数的比例

### GQM (目标-问题-度量) 的设计模版：

- **目标 (Goal)：** “提升 [系统测试] 的 [缺陷发现效率]，以降低 [线上故障率]。

  **【为了 [目的]，研究 [对象] 的 [关注点]，从 [视角] 出发，在 [环境] 中进行。”】**

  - **目的 (Purpose)**：为什么要测？（常用动词：**改进、评估、预测、了解**）
  - **对象 (Object)**：测的是什么？（通常是：**过程、产品、模型、资源**）
  - **关注点 (Focus)**：测的是对象的什么属性？（如：**准确率、成本、时延、缺陷率**）
  - **视角 (Viewpoint)**：谁在乎这个结果？（如：**项目经理、数据科学家、最终用户**）
  - **环境 (Context)**：在什么背景下测？（如：**xx项目的开发阶段、生产环境、特定的硬件平台**）

- **问题 (Question)：** “当前 [测试阶段] 拦截了百分之多少的缺陷？哪些 [模块] 是故障高发区？评审投入的时间与发现缺陷的效率是否成正比？”

- **度量 (Metric)：** “使用 [缺陷检测率 (DDP) / 缺陷密度 / 修复时长] 作为定量评估标准。”对应指标 (Metric) 必须是可采集的证据，如：**平均周期（平均每小时评审代码行数 (KLOC/hr) 或 发现单个缺陷的平均评审耗时 ）、审查合格率(代码评审发现的缺陷数 / (代码评审缺陷数 + 交付后缺陷数) )、用户满意度评分**

![image-20251229121017151](E:\Typora\Typora\coding-study\image-20251229121017151.png)

---

# 4-8 看板、WIP

**Q：DevOps的“第一步（The First Way）”强调“实现开发到运维的工作快速地从左向右流动”，而看板管理通过可视化工作流、限制在制品（WIP）等核心机制优化流程。请简单说明：看板的 “可视化工作流” 和 “WIP 限制”如何直接支撑DevOps的“第一步（The First Way）”的落地？**

>可视化工作流使“开发到运维”工作流程变得直观可见，团队成员能够更好地理解整个系统的工作流，及时关注到全局进度。
>
>WIP限制对每个状态的工作数量做出限制，减少了多任务和拥堵，促使团队协作解决阻塞，确保工作快速从左向右流动。

### 看板 (Kanban) 的价值：

- **可视化 (Visual)：** “通过可视化工作流，使 [开发到运维] 的价值链变得透明，消除‘信息孤岛’，确保团队成员对 [全局进度] 达成共识。”
- **WIP 限制 (Limit WIP)：** “WIP 限制强制团队**‘停止开始，开始完成’**，通过暴露 [下游堵塞点]，迫使资源向瓶颈处集中，从而缩短 [交付周期 (Lead Time)]。”

---

# 4-79 OKR

**Q：假设你是本课程读书报告小组的组长，计划用 OKR 推动小组在本学期内完成课程读书报告项目。请你为小组制定一套 OKR（包含 1 个 O 和 2-3 个 KR）。** 

>Object:
>
>交付一份能够深度体现本课程知识应用的报告，使其成为我们未来学术研究或工程实践的可信参考范本
>
>Key Results:
>
>1. 在课程结束前一周，进行一次小组会议（可以线上），讨论报告核心内容及架构，最终确定不少于3处对课程核心理论的应用点
>2. 在报告提交前一周，完成一次交叉审阅，每位成员记录至少2条优点与不足，并基于审阅意见达到100%的修改落实

- **Objective (O - 目标)：** 必须是**鼓舞人心、定性、有方向感**的。
  - *金句模版：* “交付一个 [改变行业标准/极大提升体验/深度融合课程理论] 的 [XX项目/产品]。”（攻克雨天感知技术难关，打造行业领先的“全天候避障”安全保障体系。）
- **Key Results (KRs - 关键结果)：** 必须是**具体的、有时限的、定量**的。
  - *KR1 (质量/深度)：* “在 [日期] 前，完成 [XX项] 核心功能的开发，且经过 [XX次] 压力测试无致命缺陷。”
  - *KR2 (反馈/应用)：* “基于 [XX理论]，完成对 [XX过程] 的 100% 优化，并获得 [利益相关者] 的书面确认。”
  - *KR3 (团队/成长)：* “组织 [XX次] 深度技术评审，识别并解决至少 [XX个] 潜在风险点。”（通过 3 轮交叉评审，识别并 100% 修复所有潜在的技术阻碍，且用户测试中的“交互流畅度”评分从 3.0 提升至 **4.5 分**。）

- “OKR 的核心价值在于**‘对齐 (Alignment)’与‘聚焦 (Focus)’**，确保团队所有成员的精力都锁死在 [核心业务价值] 上。”“KR 不是‘任务清单’，而是‘结果定义’。它强制我们思考：**如果我们做成了，世界会变成什么样？**”

---

# 5-66 AI模型与系统

**Q：假定 Lecture-5 开篇给出的“智能烤箱”案例中，数据科学家建议在生产环境中不断改进模型，并定期发布新版本。团队其他成员担心这可能会对智能烤箱用户产生影响。但数据科学家认为，他们很谨慎，每次更新只发布比前一版本准确率更高的模型，而且他们进一步认为，由于模型准确率有所提高，产品将更受欢迎。 你同意数据科学家的论点吗？简单阐述你的理由。**

>不完全同意。
>
>1. 模型的更新可能需要同步更新硬件或软件，极有可能引发兼容性问题。
>
>2. 频繁修改模型可能会操作方式的频繁更换，用户可能会因此不满。
>3. 模型准确率的提高，并不能直接代表产品会更受欢迎，实际应用过程中可能会因为地区、习俗等不同，获得不同的用户体验反馈。
>
>4. 作为一个日常用品，如果其本身的基础功能已经达到，那么就已经符合了用户的主要需求，但是过于追求模型准确率，用大量精力去提升决定用户是否会购买该产品的较小因素上，效率不高。相比之下，将这些精力投入到**改善用户界面、降低功耗、提升加热均匀性、加强安全性能或降低成本**上，可能会带来更高的市场回报和用户满意度。

### 模型准确率陷阱 (Accuracy Trap)：

- **核心观点**：模型只是系统的一个子集。不能片面追求准确率，要看是否服务于**组织目标（赚钱/用户价值）** 。
- **金句：**
  -  单纯的准确率提升并不等同于 [业务价值] 的提升。在生产环境下，必须权衡 [推理延迟/兼容性/运维成本] 等因素。
  - 虽然模型准确率提升，但从**系统视角**看，频繁更新可能带来 [负面影响，如：兼容性、用户习惯改变]，且未必能直接转化为 [组织目标，如：盈利] 
  - 模型只是系统的一个子集。虽然模型属性得到了微量提升，但如果它破坏了**系统目标（实时性）**并最终损害了**用户结果（使用爽感）**，那么这种改进在**系统视角**下是负向的
- **论据：** “过度追求高精度可能导致 [模型过拟合] 或 [计算资源浪费]，对于 [智能烤箱/家用电器] 这类设备，用户对 [操作流畅度/稳定性] 的敏感度远高于 1% 的准确率差异。”

> - **智能拐杖，提升0.01的识别精度，但增加5倍的误报率**
> - **权衡分析**：单纯追求漏报率降低会导致误报激增，这在系统中会造成“狼来了”效应，让用户最终无视或关闭警报。
> - **改进方案：** 应采用**“增强交互（Augmentation）”模式**，在系统识别到疑似跌倒时，**先通过语音播报询问老人，若无人回应再触发紧急警报**。

---

# 6-11 分层目标

**Q：针对lecture-5讨论的“智能烤箱”项目案例，其“组织目标”是为利益相关者盈利，但这是一个非常滞后的度量指标。 因此，请按lecture-6中所讨论分层目标，进一步为该项目定义更具体的“领先指标”、“系统目标”、“用户结果”、“模型属性” 。**

>领先指标：月度用户增长率提升、用户推荐意愿值高
>
>系统目标：建设更加稳健的系统，确保底层设施支撑模型平稳运行，降低用户学习使用智能功能的成本
>
>用户结果：智能功能使用率高、用户满意度高
>
>模型属性：识别食物类型准高准确率、烤制程度预测的高效率

- **组织目标**：宏观、长期（如：收入、社会福利）。【为利益相关者盈利，提升 [利益相关者] 在 [领域/行业] 声誉，并增加 [相关业务] 的收入】
- **领先指标**：短期代理（如：用户活跃度、市场占有率） 。**(Leading Indicators - 业务层)：** “关注 [用户增长率/日活/留存]。这是预测未来 [盈利/成功] 的前瞻信号。【与 [应用于该领域的企业] 合作增长率，月度处理总量】
- **系统目标**：技术建设目标（如：检测癌症、转录音频） 。**(System Goals - 软件层)：** “优化 [系统响应时间/并发处理能力/崩溃率]。确保底层设施能支撑 [AI模型] 的平稳运行，将系统故障率降低到0.1%。”（系统在检测到异常后 **3 秒内**完成多渠道警报下达，且支持 24/7 离线监测）
- **用户结果**：直接价值（如：节省的时间、点击率。 **(User Outcomes - 价值层)**  “提升 [推荐点击率/任务完成效率/用户主观评分]。体现 AI 到底给用户省了多少事、带来了多少快乐。”
- **模型属性**：技术指标（如：准确率、推理时间、成本） 。 **(Model Attributes - 算法层)：** “追求 [高准确率/召回率/F1值/低推理延迟]。这是实现上述所有目标的**‘技术原动力’**。”

---

# 7-55 部署模式

**Q： 假定你是lecture-5讨论的“智能烤箱”项目团队技术骨干，考虑模型部署模式之间的各种权衡因素，你建议采用什么样的部署模式？简单阐述你的理由。**

>采用混合智能部署模式。设备端部署一个能够覆盖大部分场景的轻量模型，确保离线操作和执行快速响应；云端部署一个模型持续学习用户数据；定期更新设备的模型
>
>更新延迟：烤箱不需要频繁的模型更新，对更新延迟要求不高；
>
>执行延迟：影响用户体验的流畅度，需要快速给出识别和推荐结果；
>
>运维成本：混合智能运维成本可控；
>
>离线操作：必须在无网络环境下完全正常工作

- **考虑因素**
  
  - **更新频率**：是否需频繁更新？采用**“在线云端更新”**，可以利用网络静默下载新模型包，解决了设备端模型容易过时的问题，实现了持续进化 
  - **在线推理延迟**：用户能否接受？由于是**“设备端推理”**，计算在本地完成，响应速度极快，无需等待网络传输，能满足用户对实时性的极致需求
  - **运维成本**：谁付钱（带宽/算力）？云端只负责分发模型更新包，不负责高频的实时推理计算，极大地**降低了服务器的算力成本和带宽开销** 。
- **离线操作**：是否必须断网可用？ 这是**“离线推理”的核心优势**。即使在断网环境下，设备的核心智能功能依然可用，保证了产品的可用性红线 
  
- **混合智能 (Hybrid)：** “采用混合部署模式可以兼顾 **‘边缘端的实时响应’**（保障 [基础功能/离线可用]）与 **‘云端的深度学习’**（实现 [跨设备数据聚合/模型长周期更新]）。”

- **权衡点：** “在评估部署模式时，必须综合考量 [执行延迟/更新带宽/数据隐私/硬件功耗] 四个关键维度。”**善用“权衡”这个词**：老师非常喜欢看到学生讨论“牺牲了什么换取了什么”。比如：“虽然这种模式增加了设备端的硬件成本（需要芯片算力），但它换取了更好的用户体验和更低的云端运维压力” 。

- **低延迟 + 隐私 + 离线可用** $\rightarrow$ **设备端（边缘）部署**

  **高算力 + 大模型 + 频繁更新** $\rightarrow$ **云端（后端）部署**

  **论证话术**：**“虽然 [模式A] 增加了 [某成本]，但它换取了 [某关键性能]，更符合 [分层目标] 中的系统目标。”**

---

# 7-99 交互模式

**Q：假定你在考虑开发一款移动应用程序APP，用户可以使用它来监控前文讨论的“智能烤箱” 。简单举一个例子说明，你认为哪种用户交互模式更适合该APP：自动化还是增强（提示、组织、注释）？**

>增强交互模式更适合该APP
>
>如果使用自动化交互模式可能会出现烤制结果难以符合用户预期、烤制过程出现安全问题无法定责、用户担心对烤箱失去控制等情况；
>
>增强模式可以向用户提供烤制选项、推送烤制进度，用户始终掌握知情和决策权。

- **增强 (Augmentation)：** “对于 [安全敏感/高度个性化] 的场景，‘增强模式’优于‘自动化’。它保留了用户的 **‘决策权与知情权’**，通过 [提示/注释] 辅助用户，避免了算法错误带来的 [法律/安全] 责任争议。”

- **考虑因素**
  - **自动化 (Automation)**：直接做决策，不问用户 。
  - **增强 (Augmentation)**：
    - **提示 (Prompt)**：弹窗询问。
    - **组织 (Organize)**：排序推荐，不打扰。
    - **注释 (Annotate)**：打标签/闪烁提醒 。